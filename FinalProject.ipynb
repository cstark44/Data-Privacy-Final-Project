{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "# SOURCED FROM TEXTBOOK 'VARIANTS OF DIFFERENTIAL PRIVACY' SECTION - adjusted from vector format\n",
    "def gaussian_mech_RDP(v, sensitivity, alpha, epsilon_bar):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon_bar))\n",
    "    return v + np.random.normal(loc=0, scale=sigma)\n",
    "\n",
    "def convert_RDP_ED(alpha, epsilon_bar, delta):\n",
    "    return epsilon_bar + np.log(1 / delta) / (alpha - 1) # From textbook\n",
    "\n",
    "df = pd.read_csv('survey.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_data_cleaning(df):\n",
    "    # Data cleaning for columns we need\n",
    "    unique_genders = df['Gender'].unique()\n",
    "\n",
    "    m = \"Male\"\n",
    "    f = \"Female\"\n",
    "    o = \"Other\"\n",
    "    map_to = [f, m, m, m, f, m, m, m, f, f, f, m, m, f, f, m, m, o, o, f, f, m, o, o, o, o, o, f, o, o, f, m, m, m, m, f, m, o, f, o, f, m, m, o, m, o, f, m, m]\n",
    "    assert len(unique_genders) == len(map_to), \"Mapping mismatch in gender data cleaning\"\n",
    "\n",
    "    # Zip together the mapping\n",
    "    gender_mapping = dict(zip(unique_genders, map_to))\n",
    "\n",
    "    # Change genders\n",
    "    df['Gender'] = df['Gender'].map(gender_mapping)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def age_data_cleaning(df):\n",
    "    # Will drop any columns where age is less than 18 or greater than 90 as this should be data on the tech industry\n",
    "    df = df[(df['Age'] >= 18) & (df[\"Age\"] <= 90)]\n",
    "    return df\n",
    "\n",
    "def yes_no_to_true_false(df, column):\n",
    "    # Will convert yes/no answers to true or false for the columns we care about\n",
    "    yes_no_mapping = {\"Yes\" : True, \"No\" : False}\n",
    "    df[column] = df[column].map(yes_no_mapping)\n",
    "    return df\n",
    "\n",
    "def drop_cols(df):\n",
    "    df = df.drop(['state', 'comments'], axis=1)\n",
    "    return df\n",
    "\n",
    "def fill_na(df, col, val):\n",
    "    df[col] = df[col].fillna(val)\n",
    "    return df\n",
    "\n",
    "def maybe_to_yes(df, col):\n",
    "    maybe_mapping = {\"Yes\": \"Yes\", \"Maybe\" : \"Yes\", \"No\" : \"No\"}\n",
    "    df[col] = df[col].map(maybe_mapping)\n",
    "    return df\n",
    "    \n",
    "df = gender_data_cleaning(df)\n",
    "df = age_data_cleaning(df)\n",
    "df = drop_cols(df)\n",
    "\n",
    "# Fill na\n",
    "df = fill_na(df, 'work_interfere', 'Never')\n",
    "df = fill_na(df, 'self_employed', 'No')\n",
    "\n",
    "# Map maybe for consequence to yes\n",
    "df = maybe_to_yes(df, 'mental_health_consequence')\n",
    "\n",
    "\n",
    "# Convert yes / no to true / false\n",
    "df = yes_no_to_true_false(df, 'treatment')\n",
    "df = yes_no_to_true_false(df, 'family_history')\n",
    "df = yes_no_to_true_false(df, 'self_employed')\n",
    "df = yes_no_to_true_false(df, 'remote_work')\n",
    "df = yes_no_to_true_false(df, 'tech_company')\n",
    "df = yes_no_to_true_false(df, 'mental_health_consequence')\n",
    "df = yes_no_to_true_false(df, 'obs_consequence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Age', 'Gender', 'Country', 'self_employed',\n",
       "       'family_history', 'treatment', 'work_interfere', 'no_employees',\n",
       "       'remote_work', 'tech_company', 'benefits', 'care_options',\n",
       "       'wellness_program', 'seek_help', 'anonymity', 'leave',\n",
       "       'mental_health_consequence', 'phys_health_consequence', 'coworkers',\n",
       "       'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
       "       'mental_vs_physical', 'obs_consequence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General thoughts for project outline\n",
    "# Maybe lets just focus on releasing what percentage of individuals have seek treatment for mental illness. Which is just 2 counting queries so it would be easy? \n",
    "# Maybe based on family history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('treatment', 'self_employed'), ('treatment', 'family_history'), ('treatment', 'remote_work'), ('treatment', 'tech_company'), ('treatment', 'mental_health_consequence'), ('treatment', 'obs_consequence')]\n",
      "[75, 362, 195, 510, 422, 125]\n"
     ]
    }
   ],
   "source": [
    "# Create workload\n",
    "colsToCompare = ['self_employed', 'family_history', 'remote_work', 'tech_company', 'mental_health_consequence', 'obs_consequence']\n",
    "\n",
    "# Make query\n",
    "def association_query(df, col1, col2):\n",
    "    return len(df[(df[col1] == True) & (df[col2] == True)])\n",
    "\n",
    "workload = []\n",
    "for col in colsToCompare:\n",
    "    workload.append(('treatment', col))\n",
    "\n",
    "real_answers = [association_query(df, col1, col2) for (col1, col2) in workload]\n",
    "\n",
    "print(workload)\n",
    "print(real_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75.45872306378985,\n",
       " 364.0571875549476,\n",
       " 197.13503692217367,\n",
       " 505.9795574923418,\n",
       " 420.5725839317929,\n",
       " 137.72383088350483]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epsilon DP\n",
    "def workload_laplace(workload, epsilon):\n",
    "    # Determine individual i's \n",
    "    epsilon_i = epsilon / len(workload)\n",
    "    queries = [association_query(df, col1, col2) for (col1, col2) in workload]\n",
    "    return [laplace_mech(query, sensitivity=1, epsilon=epsilon_i) for query in queries]\n",
    "\n",
    "workload_laplace(workload, 1.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error: 48.397871605531584\n"
     ]
    }
   ],
   "source": [
    "errors = [abs(r_a - l_a) for (r_a, l_a) in zip(real_answers, workload_laplace(workload, 0.1))]\n",
    "print('Average absolute error:', np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.285149221552242\n",
      "True: 0.7402862985685071 \n",
      "Noisy: 0.6245901707065193\n",
      "True: 362, Noisy: 356.3327113742949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Epsilon Delta DP\n",
    "def workload_laplace_vec(workload, epsilon):\n",
    "    queries = [association_query(df, col1, col2) for (col1, col2) in workload]\n",
    "    \n",
    "    # L1 global sensitivity is equal to adding all the sensitivities up \n",
    "    # Each query has a sensitivity of 1 so the L1 sensitivity is equal to len(queries)\n",
    "    sens = len(queries)\n",
    "    return laplace_mech_vec(queries, sensitivity=sens, epsilon=epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.181112133455024\n",
      "True: 0.5051958433253397 \n",
      "Noisy: 0.6628944772433413\n",
      "True: 632, Noisy: 735.8012421284712\n",
      "Error: 31.215346682186695\n"
     ]
    }
   ],
   "source": [
    "# Epsilon Delta DP - Seek treatment\n",
    "error_total = 0\n",
    "for _ in range(100):\n",
    "    true_num = df['treatment'].sum()\n",
    "    total_people = df['treatment'].count()\n",
    "\n",
    "    epsilon = 0.1\n",
    "    noisy_num = gaussian_mech(true_num, 1, epsilon/2, 1e-5)\n",
    "    noisy_total = gaussian_mech(total_people, 1, epsilon/2, 1e-5)\n",
    "\n",
    "    error_total += pct_error(true_num / total_people, noisy_num / noisy_total)\n",
    "\n",
    "print(error_total / 100)\n",
    "\n",
    "\n",
    "print(f\"True: {true_num / total_people} \\nNoisy: {noisy_num / noisy_total}\")\n",
    "print(f\"True: {true_num}, Noisy: {noisy_num}\")\n",
    "print(f\"Error: {pct_error(true_num / total_people, noisy_num / noisy_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renyi DP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data DP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
