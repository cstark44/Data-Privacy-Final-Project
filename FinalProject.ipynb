{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def laplace_mech_vec(vec, sensitivity, epsilon):\n",
    "    return [v + np.random.laplace(loc=0, scale=sensitivity / epsilon) for v in vec]\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def gaussian_mech_vec(vec, sensitivity, epsilon, delta):\n",
    "    return [v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "            for v in vec]\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "# SOURCED FROM TEXTBOOK 'VARIANTS OF DIFFERENTIAL PRIVACY' SECTION - adjusted from vector format\n",
    "def gaussian_mech_RDP(v, sensitivity, alpha, epsilon_bar):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon_bar))\n",
    "    return v + np.random.normal(loc=0, scale=sigma)\n",
    "\n",
    "def convert_RDP_ED(alpha, epsilon_bar, delta):\n",
    "    return epsilon_bar + np.log(1 / delta) / (alpha - 1) # From textbook\n",
    "\n",
    "df = pd.read_csv('survey.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_data_cleaning(df):\n",
    "    # Data cleaning for columns we need\n",
    "    unique_genders = df['Gender'].unique()\n",
    "\n",
    "    m = \"Male\"\n",
    "    f = \"Female\"\n",
    "    o = \"Other\"\n",
    "    map_to = [f, m, m, m, f, m, m, m, f, f, f, m, m, f, f, m, m, o, o, f, f, m, o, o, o, o, o, f, o, o, f, m, m, m, m, f, m, o, f, o, f, m, m, o, m, o, f, m, m]\n",
    "    assert len(unique_genders) == len(map_to), \"Mapping mismatch in gender data cleaning\"\n",
    "\n",
    "    # Zip together the mapping\n",
    "    gender_mapping = dict(zip(unique_genders, map_to))\n",
    "\n",
    "    # Change genders\n",
    "    df['Gender'] = df['Gender'].map(gender_mapping)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def age_data_cleaning(df):\n",
    "    # Will drop any columns where age is less than 18 or greater than 90 as this should be data on the tech industry\n",
    "    df = df[(df['Age'] >= 18) & (df[\"Age\"] <= 90)]\n",
    "    return df\n",
    "\n",
    "def yes_no_to_true_false(df, column):\n",
    "    # Will convert yes/no answers to true or false for the columns we care about\n",
    "    yes_no_mapping = {\"Yes\" : True, \"No\" : False}\n",
    "    df[column] = df[column].map(yes_no_mapping)\n",
    "    return df\n",
    "\n",
    "def drop_cols(df):\n",
    "    df = df.drop(['state', 'comments'], axis=1)\n",
    "    return df\n",
    "\n",
    "def fill_na(df, col, val):\n",
    "    df[col] = df[col].fillna(val)\n",
    "    return df\n",
    "\n",
    "def maybe_to_yes(df, col):\n",
    "    maybe_mapping = {\"Yes\": \"Yes\", \"Maybe\" : \"Yes\", \"No\" : \"No\"}\n",
    "    df[col] = df[col].map(maybe_mapping)\n",
    "    return df\n",
    "    \n",
    "df = gender_data_cleaning(df)\n",
    "df = age_data_cleaning(df)\n",
    "df = drop_cols(df)\n",
    "\n",
    "# Fill na\n",
    "df = fill_na(df, 'work_interfere', 'Never')\n",
    "df = fill_na(df, 'self_employed', 'No')\n",
    "\n",
    "# Map maybe for consequence to yes\n",
    "df = maybe_to_yes(df, 'mental_health_consequence')\n",
    "\n",
    "\n",
    "# Convert yes / no to true / false\n",
    "df = yes_no_to_true_false(df, 'treatment')\n",
    "df = yes_no_to_true_false(df, 'family_history')\n",
    "df = yes_no_to_true_false(df, 'self_employed')\n",
    "df = yes_no_to_true_false(df, 'remote_work')\n",
    "df = yes_no_to_true_false(df, 'tech_company')\n",
    "df = yes_no_to_true_false(df, 'mental_health_consequence')\n",
    "df = yes_no_to_true_false(df, 'obs_consequence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General thoughts for project outline\n",
    "# Maybe lets just focus on releasing what percentage of individuals have seek treatment for mental illness. Which is just 2 counting queries so it would be easy? \n",
    "# Maybe based on family history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('treatment', 'self_employed'), ('treatment', 'family_history'), ('treatment', 'remote_work'), ('treatment', 'tech_company'), ('treatment', 'mental_health_consequence'), ('treatment', 'obs_consequence')]\n",
      "[75, 362, 195, 510, 422, 125]\n"
     ]
    }
   ],
   "source": [
    "# Create workload\n",
    "colsToCompare = ['self_employed', 'family_history', 'remote_work', 'tech_company', 'mental_health_consequence', 'obs_consequence']\n",
    "\n",
    "# Make query\n",
    "def association_query(df, col1, col2):\n",
    "    return len(df[(df[col1] == True) & (df[col2] == True)])\n",
    "\n",
    "workload = []\n",
    "for col in colsToCompare:\n",
    "    workload.append(('treatment', col))\n",
    "\n",
    "real_answers = [association_query(df, col1, col2) for (col1, col2) in workload]\n",
    "\n",
    "print(workload)\n",
    "print(real_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54.29376765181739,\n",
       " 326.9781693493864,\n",
       " 190.5037374230667,\n",
       " 522.5326223400823,\n",
       " 379.7297031659281,\n",
       " 67.25580080073284]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epsilon DP\n",
    "def workload_laplace(workload, epsilon):\n",
    "    # Determine individual i's \n",
    "    epsilon_i = epsilon / len(workload)\n",
    "    queries = [association_query(df, col1, col2) for (col1, col2) in workload]\n",
    "    return [laplace_mech(query, sensitivity=1, epsilon=epsilon_i) for query in queries]\n",
    "\n",
    "workload_laplace(workload, 0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error: 76.38737710196779\n"
     ]
    }
   ],
   "source": [
    "errors = [abs(r_a - l_a) for (r_a, l_a) in zip(real_answers, workload_laplace(workload, 0.1))]\n",
    "print('Average absolute error:', np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[133.12888148748098,\n",
       " 350.7386573682376,\n",
       " 207.7164229051883,\n",
       " 487.98906489353146,\n",
       " 414.5467567460243,\n",
       " 142.63891845362744]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epsilon Delta DP\n",
    "def workload_laplace_vec(workload, epsilon):\n",
    "    queries = [association_query(df, col1, col2) for (col1, col2) in workload]\n",
    "    \n",
    "    # L1 global sensitivity is equal to adding all the sensitivities up \n",
    "    # Each query has a sensitivity of 1 so the L1 sensitivity is equal to len(queries)\n",
    "    sens = len(queries)\n",
    "    return laplace_mech_vec(queries, sensitivity=sens, epsilon=epsilon)\n",
    "\n",
    "workload_laplace_vec(workload, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error: 43.17463414492229\n"
     ]
    }
   ],
   "source": [
    "errors = [abs(r_a - l_a) for (r_a, l_a) in zip(real_answers, workload_laplace_vec(workload, 0.1))]\n",
    "print('Average absolute error:', np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28.641905527861027,\n",
       " 494.2590118303943,\n",
       " 462.6170545448808,\n",
       " 556.1634949396387,\n",
       " 384.9666926083772,\n",
       " 302.2073776311055]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def workload_gaussian_vec(workload, epsilon, delta):\n",
    "    queries = [association_query(df, col1, col2) for (col1, col2) in workload]\n",
    "\n",
    "    # L2 global sensitivity should be used here \n",
    "    # L2 sens = squares of individual sensitivities added up then square rooted - each sensitivity is 1 because this is a counting query\n",
    "    # L2 sens = sqrt(len(queries))\n",
    "    return gaussian_mech_vec(queries, sensitivity=np.sqrt(len(queries)), epsilon=epsilon, delta=delta)\n",
    "\n",
    "workload_gaussian_vec(workload, 0.1, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error: 88.96677667979709\n"
     ]
    }
   ],
   "source": [
    "errors = [abs(r_a - l_a) for (r_a, l_a) in zip(real_answers, workload_gaussian_vec(workload, 0.1, 1e-5))]\n",
    "print('Average absolute error:', np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77.79243621353002,\n",
       " 378.2934531682524,\n",
       " 171.38686673951713,\n",
       " 499.6250885254848,\n",
       " 413.4182496551203,\n",
       " 135.91234258716474]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renyi DP\n",
    "# SOURCED FROM TEXTBOOK 'VARIANTS OF DIFFERENTIAL PRIVACY' SECTION\n",
    "def gaussian_mech_RDP_vec(vec, sensitivity, alpha, epsilon_bar):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon_bar))\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]\n",
    "\n",
    "def workload_gaussian_vec_RDP(workload, alpha, epsilon_bar):\n",
    "    queries = [association_query(df, col1, col2) for (col1, col2) in workload]\n",
    "\n",
    "    # L2 global sensitivity should be used here as well\n",
    "    # L2 sens = squares of individual sensitivities added up then square rooted - each sensitivity is 1 because this is a counting query\n",
    "    # L2 sens = sqrt(len(queries))\n",
    "    return gaussian_mech_RDP_vec(queries, sensitivity=np.sqrt(len(queries)), alpha=alpha, epsilon_bar=epsilon_bar)\n",
    "\n",
    "workload_gaussian_vec_RDP(workload, 5, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error: 10.27736736205218\n"
     ]
    }
   ],
   "source": [
    "errors = [abs(r_a - l_a) for (r_a, l_a) in zip(real_answers, workload_gaussian_vec_RDP(workload, 5, 0.1))]\n",
    "print('Average absolute error:', np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data DP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
